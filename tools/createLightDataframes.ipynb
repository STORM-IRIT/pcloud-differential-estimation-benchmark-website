{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in c:\\users\\arnal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\arnal\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/larnalan/.local/lib/python3.10/site-packages/')\n",
    "# sys.path.insert(1, '/home/leo/.local/lib/python3.10/site-packages')\n",
    "# Install dependencies\n",
    "# check if already installed\n",
    "if not 'pandas' in sys.modules:\n",
    "    !pip install pandas\n",
    "if not 'plotly' in sys.modules:\n",
    "    !pip install plotly\n",
    "if not 'kaleido' in sys.modules:\n",
    "    !pip install -U kaleido\n",
    "# if not 'ipykernel' in sys.modules:\n",
    "# !pip install ipykernel\n",
    "# !pip install --upgrade nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import visualization_tools as vt\n",
    "import toolbox as tb\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTATION = \"PCPNet\"\n",
    "# EXPERIMENTATION = \"DGTal\"\n",
    "EXPERIMENTATION = \"Numerical\"\n",
    "# EXPERIMENTATION = \"CAD\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the code: # nbPoints radius noise-position noise-normal {avg,max,variance} for [nbNeighbors,mean,gauss,k1,k2,d1,d2,timings, pos, iShape, normal] non_stable_ratio and variant-name\\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_implicit() :\n",
    "    stats_dir_implicit_double = \"./double/implicit/\"\n",
    "    stats_dir_implicit_double_outlier = \"./double/flip/\"\n",
    "    stats_dir_implicit_double_flip = \"./double/outlier/\"\n",
    "    stats_dir_implicit_double_helios = \"./double/implicit_helios/\"\n",
    "\n",
    "    stats_dir_implicit_float = \"./float/implicit/\"\n",
    "\n",
    "    data_list = []\n",
    "    data_list.append(tb.open_data_all(stats_dir_implicit_double, added_param=[[\"expe\", \"DGTal\"], [\"type\", \"double\"], [\"dataset\", \"implicit\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_implicit_double_outlier, added_param=[[\"expe\", \"DGTal\"],[\"type\", \"double\"], [\"dataset\", \"outlier\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_implicit_double_flip, added_param=[[\"expe\", \"DGTal\"],[\"type\", \"double\"], [\"dataset\", \"flip\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_implicit_double_helios, added_param=[[\"expe\", \"DGTal\"],[\"type\", \"double\"], [\"dataset\", \"helios\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_implicit_float, added_param=[[\"expe\", \"DGTal\"],[\"type\", \"float\"], [\"dataset\", \"implicit\"]], recursive=False))\n",
    "\n",
    "    data = pd.concat(data_list)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def stats_CAD() :\n",
    "    stats_dir_CAD = \"./double/CAD/\"\n",
    "    stats_dir_CAD_helios = \"./double/CAD_helios/\"\n",
    "    \n",
    "    stats_dir_CAD_kNNgraph = \"./double/CAD_kNNgraph/\"\n",
    "    stats_dir_CAD_helios_kNNgraph = \"./double/CAD_helios_kNNgraph/\"\n",
    "    \n",
    "    data_list=[]\n",
    "    data_list.append(tb.open_data_all(stats_dir_CAD, added_param=[[\"expe\", \"CAD\"], [\"type\", \"double\"], [\"dataset\", \"CAD\"], [\"struct\", \"kD-Tree\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_CAD_helios, added_param=[[\"expe\", \"CAD\"],[\"type\", \"double\"], [\"dataset\", \"helios\"], [\"struct\", \"kD-Tree\"]], recursive=False))\n",
    "    \n",
    "    data_list.append(tb.open_data_all(stats_dir_CAD_kNNgraph, added_param=[[\"expe\", \"CAD\"],[\"type\", \"double\"], [\"dataset\", \"CAD\"], [\"struct\", \"kNN-graph\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_CAD_helios_kNNgraph, added_param=[[\"expe\", \"CAD\"],[\"type\", \"double\"], [\"dataset\", \"helios\"],[\"struct\", \"kNN-graph\"]], recursive=False))\n",
    "    data = pd.concat(data_list)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def stats_PCPNet():\n",
    "    stats_dir_PCPNet_nonoise = \"./double/PCPNet/testset_no_noise/\"\n",
    "    stats_dir_PCPNet_lownoise = \"./double/PCPNet/testset_low_noise/\"\n",
    "    stats_dir_PCPNet_mednoise = \"./double/PCPNet/testset_med_noise/\"\n",
    "    stats_dir_PCPNet_highnoise = \"./double/PCPNet/testset_high_noise/\"\n",
    "    stats_dir_PCPNet_gradient = \"./double/PCPNet/testset_vardensity_gradient/\"\n",
    "    stats_dir_PCPNet_striped = \"./double/PCPNet/testset_vardensity_striped/\"\n",
    "    \n",
    "    data_list=[]\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_nonoise, added_param=[[\"expe\", \"PCPNet\"], [\"type\", \"double\"], [\"noise_type\", \"no\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_lownoise, added_param=[[\"expe\", \"PCPNet\"],[\"type\", \"double\"], [\"noise_type\", \"low\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_mednoise, added_param=[[\"expe\", \"PCPNet\"],[\"type\", \"double\"], [\"noise_type\", \"med\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_highnoise, added_param=[[\"expe\", \"PCPNet\"],[\"type\", \"double\"], [\"noise_type\", \"high\"]], recursive=False))\n",
    "\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_gradient, added_param=[[\"expe\", \"PCPNet\"],[\"type\", \"double\"], [\"noise_type\", \"gradient\"]], recursive=False))\n",
    "    data_list.append(tb.open_data_all(stats_dir_PCPNet_striped, added_param=[[\"expe\", \"PCPNet\"],[\"type\", \"double\"], [\"noise_type\", \"striped\"]], recursive=False))\n",
    "    \n",
    "    data = pd.concat(data_list)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data[\"Noise position\"] = -1\n",
    "    data.loc[data[\"noise_type\"]==\"no\", \"Noise position\"] = 0\n",
    "    data.loc[data[\"noise_type\"]==\"low\", \"Noise position\"] = 1\n",
    "    data.loc[data[\"noise_type\"]==\"med\", \"Noise position\"] = 2\n",
    "    data.loc[data[\"noise_type\"]==\"high\", \"Noise position\"] = 3\n",
    "\n",
    "    # rename Radius column to kNN\n",
    "    data = data.rename(columns={\"Radius\": \"kNN\"})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "\\\\wsl.localhost\\Ubuntu\\home\\arnalleo\\applications_ubuntu\\AppWeb\\tools\\toolbox.py:128: FutureWarning:\n",
      "\n",
      "The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "C:\\Users\\arnal\\AppData\\Local\\Temp\\ipykernel_25356\\3126956668.py:33: MatplotlibDeprecationWarning:\n",
      "\n",
      "The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if EXPERIMENTATION == \"PCPNet\" :\n",
    "    data_all = stats_PCPNet()\n",
    "elif EXPERIMENTATION == \"DGTal\" or EXPERIMENTATION == \"Numerical\" :\n",
    "    data_all = stats_implicit()\n",
    "elif EXPERIMENTATION == \"CAD\" :\n",
    "    data_all = stats_CAD()\n",
    "else :\n",
    "    print(\"EXPERIMENTATION not found\")\n",
    "    exit()\n",
    "\n",
    "for i, noise_p in enumerate (data_all[\"Noise position\"].unique()) :\n",
    "    data_all.loc[data_all[\"Noise position\"]==noise_p, \"Noise position class\"] = i\n",
    "for j, noise_n in enumerate(data_all[\"Noise normal\"].unique()) :\n",
    "    data_all.loc[data_all[\"Noise normal\"]==noise_n, \"Noise normal class\"] = j\n",
    "\n",
    "for k in range(len(data_all[\"Noise position\"].unique())) :\n",
    "    # put noise class to k when noise position class is k and noise normal class is k\n",
    "    data_all.loc[(data_all[\"Noise position class\"]==k) & (data_all[\"Noise normal class\"]==k), \"Noise class\"] = k\n",
    "# other, put noise class to -1\n",
    "data_all.loc[data_all[\"Noise class\"].isna(), \"Noise class\"] = -1\n",
    "\n",
    "# Timings (mean) from nanosecond to millisecond\n",
    "data_all[\"Timings (mean)\"] = data_all[\"Timings (mean)\"] / 1e6\n",
    "\n",
    "data_all_methods = data_all.copy()\n",
    "\n",
    "all_methods, methods = tb.methods(data_all, True)\n",
    "\n",
    "data_all = data_all[data_all[\"Method\"].isin(all_methods)]\n",
    "\n",
    "color_map_method = {}\n",
    "for method in all_methods:\n",
    "    color_map_method[method] = plt.cm.get_cmap(\"tab20\")(all_methods.index(method))\n",
    "\n",
    "# map the colormap but as rgba value such as 'rgba(x, x, x, 1)' with x between 0 and 256\n",
    "color_map_to_value = {} \n",
    "color_map_to_value_soft = {} \n",
    "for method in color_map_method.keys() :\n",
    "    color_map_to_value[method] = \"rgba(\" + str(int(color_map_method[method][0]*255)) + \", \" + str(int(color_map_method[method][1]*255)) + \", \" + str(int(color_map_method[method][2]*255)) + \", 1)\"\n",
    "    color_map_to_value_soft[method] = \"rgba(\" + str(int(color_map_method[method][0]*255)) + \", \" + str(int(color_map_method[method][1]*255)) + \", \" + str(int(color_map_method[method][2]*255)) + \", 0.2)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_dataframe(data, for_what, constraint, x_label, y_label, divider=None):\n",
    "    \"\"\"\n",
    "    This function will create all the possible plots, to be given to a statique plot function later.\n",
    "    ie : for each possible x_label, y_label, divider, constraint, it will create (name, x, y) data to be plotted.\n",
    "    \"\"\"\n",
    "    data_out = {}\n",
    "\n",
    "    data_constrained = data[data[constraint[0]].isin(constraint[1])]\n",
    "    for what in data_constrained[for_what].unique():\n",
    "        data_what = data_constrained[data_constrained[for_what]==what]\n",
    "\n",
    "        \n",
    "        data_x = [float(x) if isinstance(x, (int, float, np.number)) else x for x in sorted(data_what[x_label].unique())]\n",
    "        data_x = [x for x in data_x if not pd.isna(x)]\n",
    "        \n",
    "\n",
    "        if divider is not None and divider in data_what.columns:\n",
    "            for dev in data_what[divider].unique():\n",
    "                data_y = []\n",
    "                for x in data_x:\n",
    "                    mean_value = data_what[(data_what[x_label]==x) & (data_what[divider]==dev)][y_label].mean()\n",
    "                    if not pd.isna(mean_value):\n",
    "                        data_y.append(float(mean_value))\n",
    "                if data_y:\n",
    "                    data_out[f'{what}_{dev}'] = [data_x, data_y]\n",
    "        else:\n",
    "            data_y = []\n",
    "            for x in data_x:\n",
    "                mean_value = data_what[data_what[x_label]==x][y_label].mean()\n",
    "                if not pd.isna(mean_value):\n",
    "                    data_y.append(float(mean_value))\n",
    "                else:\n",
    "                    data_y.append(-1)\n",
    "            \n",
    "            if data_y:\n",
    "                data_out[what] = [data_x, data_y]\n",
    "\n",
    "    return data_out\n",
    "\n",
    "# Usage example:\n",
    "# constraint_test = possible_constraints[0]\n",
    "# test_data = create_sub_dataframe(data_all, \"Method\", constraint_test, \"Radius\", \"Mean curvature (mean)\", \"kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_tsx_data(dataframe, possible_x_labels, possible_y_labels, possible_dividers, constraints):\n",
    "    plot_data = {}\n",
    "    \n",
    "    # keys = [\"Method\", \"Shape\", \"N\"]\n",
    "    keys = [\"Method\"]\n",
    "\n",
    "    for constraint in constraints:\n",
    "        constraint_description = constraint[2]\n",
    "        for for_what in keys:\n",
    "            for x_label in possible_x_labels:\n",
    "                for y_label in possible_y_labels:\n",
    "                    for divider in possible_dividers + [None]:\n",
    "                        divider_name = f'_{divider}'\n",
    "                        if divider is None :\n",
    "                            divider_name = \"\"\n",
    "                        elif divider not in dataframe.columns :\n",
    "                            continue\n",
    "                        key = f\"{constraint_description}_{x_label}_{y_label}{divider_name}\"\n",
    "                        data = create_sub_dataframe(dataframe, for_what, constraint, x_label, y_label, divider )\n",
    "                        plot_data[key] = data\n",
    "    return plot_data\n",
    "\n",
    "# plot_data = dataframe_to_tsx_data(data_all, possible_x_labels, possible_y_labels, possible_dividers, possible_constraints)\n",
    "# print (plot_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_types_file(file_name):\n",
    "    content = \"\"\"\n",
    "export interface PlotDataType {\n",
    "  [method: string]: [number[], number[]];\n",
    "}\n",
    "\n",
    "export interface PlotDataSet {\n",
    "  xLabels: string[];\n",
    "  yLabels: string[];\n",
    "  dividers: string[];\n",
    "  constraints: string[];\n",
    "  data: {\n",
    "    [key: string]: PlotDataType;\n",
    "  };\n",
    "  colorMap: {\n",
    "    [method: string]: string;\n",
    "  };\n",
    "}\n",
    "\n",
    "export interface PlotDataAccessors {\n",
    "  getXLabels: () => string[];\n",
    "  getYLabels: () => string[];\n",
    "  getDividers: () => string[];\n",
    "  getConstraints: () => string[];\n",
    "  getData: () => { [key: string]: PlotDataType };\n",
    "  getDataForKey: (key: string) => PlotDataType | undefined;\n",
    "  getSpecificData: (xLabel: string, yLabel: string, divider: string | null, constraint: string | null) => PlotDataType | null;\n",
    "  getColorMap : () => { [method: string]: string };\n",
    "}\n",
    "\"\"\"\n",
    "    file_path = f\"{file_name}.ts\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)\n",
    "    print(f\"File {file_path} has been created.\")\n",
    "\n",
    "def generate_tsx_content(data, x_labels, y_labels, dividers, constraints, color_map, file_name):\n",
    "    content = f\"\"\"\n",
    "import {{ PlotDataType, PlotDataSet, PlotDataAccessors }} from '../types';\n",
    "\n",
    "const {file_name}: PlotDataSet = {{\n",
    "    xLabels: {x_labels},\n",
    "    yLabels: {y_labels},\n",
    "    dividers: {dividers},\n",
    "    constraints: {constraints},\n",
    "    data: {data},\n",
    "    colorMap: {color_map},\n",
    "}};\n",
    "\n",
    "export const getXLabels = (): string[] => {file_name}.xLabels;\n",
    "export const getYLabels = (): string[] => {file_name}.yLabels;\n",
    "export const getDividers = (): string[] => {file_name}.dividers;\n",
    "export const getConstraints = (): string[] => {file_name}.constraints;\n",
    "export const getData = (): {{ [key: string]: PlotDataType }} => {file_name}.data;\n",
    "export const getDataForKey = (key: string): PlotDataType | undefined => {file_name}.data[key];\n",
    "\n",
    "export const getSpecificData = (xLabel: string, yLabel: string, divider: string | null, constraint: string | null): PlotDataType | null => {{\n",
    "    const xIndex = {file_name}.xLabels.indexOf(xLabel);\n",
    "    const yIndex = {file_name}.yLabels.indexOf(yLabel);\n",
    "    \n",
    "    if (xIndex === -1 || yIndex === -1) {{\n",
    "        console.error('Invalid xLabel or yLabel');\n",
    "        return null;\n",
    "    }}\n",
    "\n",
    "    let key = `${{constraint || 'overall'}}_${{xLabel}}_${{yLabel}}`;\n",
    "    if (divider) {{\n",
    "        key = `${{key}}_${{divider}}`;\n",
    "    }}\n",
    "\n",
    "    const dataForKey = {file_name}.data[key];\n",
    "    if (!dataForKey) {{\n",
    "        console.error('No data found for the given parameters');\n",
    "        return null;\n",
    "    }}\n",
    "\n",
    "    return dataForKey;\n",
    "}};\n",
    "\n",
    "export const getColorMap = (): {{ [method: string]: string }} => {file_name}.colorMap;\n",
    "\n",
    "const {file_name}Accessors: PlotDataAccessors = {{\n",
    "    getXLabels,\n",
    "    getYLabels,\n",
    "    getDividers,\n",
    "    getConstraints,\n",
    "    getData,\n",
    "    getDataForKey,\n",
    "    getSpecificData,\n",
    "    getColorMap,\n",
    "}};\n",
    "\n",
    "export default {file_name}Accessors;\n",
    "\"\"\"\n",
    "    return content\n",
    "\n",
    "def write_tsx_file(content, file_name):\n",
    "    file_path = f\"{file_name}.tsx\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)\n",
    "    print(f\"File {file_path} has been created.\")\n",
    "\n",
    "def convert_dict_to_tsx(dataframe, x_labels, y_labels, dividers, constraints, file_name):\n",
    "    contraints_description_list = [f'{constraint[2]}' for constraint in constraints]\n",
    "    dividers_list = [divider for divider in dividers if divider in dataframe.columns]\n",
    "    data_dict = dataframe_to_tsx_data(dataframe, x_labels, y_labels, dividers, constraints)\n",
    "    content = generate_tsx_content(data_dict, x_labels, y_labels, dividers_list, contraints_description_list, color_map_to_value, file_name)\n",
    "    write_tsx_file(content, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File types.ts has been created.\n"
     ]
    }
   ],
   "source": [
    "generate_types_file(\"types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCAD_tsx(dataframe):\n",
    "    # Conditions et choix pour la colonne 'noise & struct==\"kNN-graph\"'\n",
    "    data = dataframe.copy()\n",
    "    data = data[data[\"expe\"] == \"CAD\"]\n",
    "\n",
    "    # Create the column 'noise' with the following values:\n",
    "    data.loc[(data[\"dataset\"] == \"helios\") & (data[\"Noise normal\"] == 0) & (data[\"struct\"] == \"kD-Tree\"),\"noise\"] = \"Helios no noise kD-Tree\"\n",
    "    data.loc[(data[\"dataset\"] == \"helios\") & (data[\"Noise normal\"] != 0) & (data[\"struct\"] == \"kD-Tree\"),\"noise\"] = \"Helios noise kD-Tree\"\n",
    "    data.loc[(data[\"dataset\"] == \"CAD\") & (data[\"Noise normal\"] == 0) & (data[\"struct\"] == \"kD-Tree\"),\"noise\"] = \"CAD no noise kD-Tree\"\n",
    "    data.loc[(data[\"dataset\"] == \"CAD\") & (data[\"Noise normal\"] != 0) & (data[\"struct\"] == \"kD-Tree\"),\"noise\"] = \"CAD noise kD-Tree\"\n",
    "    data.loc[(data[\"dataset\"] == \"helios\") & (data[\"Noise normal\"] == 0) & (data[\"struct\"] == \"kNN-graph\"),\"noise\"] = \"Helios no noise kNN-graph\"\n",
    "    data.loc[(data[\"dataset\"] == \"helios\") & (data[\"Noise normal\"] != 0) & (data[\"struct\"] == \"kNN-graph\"),\"noise\"] = \"Helios noise kNN-graph\"\n",
    "    data.loc[(data[\"dataset\"] == \"CAD\") & (data[\"Noise normal\"] == 0) & (data[\"struct\"] == \"kNN-graph\"),\"noise\"] = \"CAD no noise kNN-graph\"\n",
    "    data.loc[(data[\"dataset\"] == \"CAD\") & (data[\"Noise normal\"] != 0) & (data[\"struct\"] == \"kNN-graph\"),\"noise\"] = \"CAD noise kNN-graph\"\n",
    "\n",
    "    possible_x_labels=[\"Radius\", \"Noise normal\", \"Shape\", \"struct\"]\n",
    "    possible_y_labels=[\"N\", 'Nb neighbors (mean)', \"normal mean\", \"Timings (mean)\", \"non_stable_ratio\"]\n",
    "    possible_dividers=[]\n",
    "    \n",
    "    noise_all = data[\"noise\"].unique()\n",
    "\n",
    "    possible_constraints=[\n",
    "        (\"noise\", noise_all, \"all\"),\n",
    "        (\"noise\", [\"CAD no noise kD-Tree\"], \"No noise kD-Tree\"),\n",
    "        (\"noise\", [\"Helios no noise kD-Tree\"], \"Helios kD-Tree\"),\n",
    "        (\"noise\", [\"CAD noise kD-Tree\"], \"Noise normal kD-Tree\"),\n",
    "        (\"noise\", [\"Helios noise kD-Tree\"], \"Helios + noise normal kD-Tree\"),\n",
    "        (\"noise\", [\"CAD no noise kNN-graph\"], \"No noise kNN-graph\"),\n",
    "        (\"noise\", [\"Helios no noise kNN-graph\"], \"Helios kNN-graph\"),\n",
    "        (\"noise\", [\"CAD noise kNN-graph\"], \"Noise normal kNN-graph\"),\n",
    "        (\"noise\", [\"Helios noise kNN-graph\"], \"Helios + noise normal kNN-graph\"),\n",
    "    ]\n",
    "    convert_dict_to_tsx(data, possible_x_labels, possible_y_labels, possible_dividers, possible_constraints, \"CAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImplicit_tsx(dataframe):\n",
    "    data = dataframe.copy()\n",
    "    data = data[data[\"expe\"] == \"DGTal\"]\n",
    "    data = data[data[\"type\"] == \"double\"]\n",
    "    \n",
    "    data.loc[(data[\"dataset\"] == \"flip\"), \"noise\"] = \"flip\"\n",
    "    data.loc[ (data[\"dataset\"] == \"outlier\"), \"noise\"] = \"outlier\"\n",
    "    data.loc[ (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] == 0), \"noise\"] = \"no noise\"\n",
    "    data.loc[ (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] != 0), \"noise\"] = \"noise\"\n",
    "    data.loc[ (data[\"dataset\"] == \"implicit\") & (data[\"Noise normal\"] == 0), \"noise precision\"] = \"noise position\"\n",
    "    data.loc[ (data[\"dataset\"] == \"implicit\") & (data[\"Noise position\"] == 0), \"noise precision\"] = \"noise normal\"\n",
    "    data.loc[ (data[\"dataset\"] == \"helios\") & (data[\"Noise class\"] == 0), \"noise\"] = \"Helios no noise\"\n",
    "    data.loc[ (data[\"dataset\"] == \"helios\") & (data[\"Noise class\"] != 0), \"noise\"] = \"Helios noise\"\n",
    "\n",
    "    # print (data[\"noise\"].unique())\n",
    "    possible_x_labels=[\"Radius\", \"Noise position\", \"Noise class\", \"Noise normal\", \"flip-normal\", \"Shape\"]\n",
    "    possible_y_labels=[\"N\", 'Nb neighbors (mean)', 'Mean curvature (mean)', 'Gaussian curvature (mean)', \"K1 mean\",\"K2 mean\",\"D1 mean\", \"D2 mean\", \"pos mean\", \"iShape mean\", \"normal mean\", \"Timings (mean)\", \"non_stable_ratio\"]\n",
    "    possible_dividers=[]\n",
    "    noise_all = data[\"noise\"].unique()\n",
    "\n",
    "    possible_constraints=[\n",
    "        (\"noise\", noise_all, \"all\"),\n",
    "        (\"noise\", [\"no noise\"], \"No noise\"),\n",
    "        (\"noise\", [\"noise\"], \"Noise\"),\n",
    "        (\"noise precision\", [\"noise position\"], \"Noise position\"),\n",
    "        (\"noise precision\", [\"noise normal\"], \"Noise normal\"),\n",
    "        (\"noise\", [\"Helios no noise\"], \"Helios no noise\"),\n",
    "        (\"noise\", [\"Helios noise\"], \"Helios normal noise\"),\n",
    "        (\"dataset\", [\"flip\"], \"Flip\"),\n",
    "        (\"dataset\", [\"outlier\"], \"Outlier\"),\n",
    "    ]\n",
    "    convert_dict_to_tsx(data, possible_x_labels, possible_y_labels, possible_dividers, possible_constraints, \"DGTal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNumerical_tsx(dataframe):\n",
    "    data = dataframe.copy()\n",
    "    data = data[data[\"expe\"] == \"DGTal\"]\n",
    "\n",
    "    data.loc[(data[\"type\"] == \"double\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] == 0), \"double noise\"] = \"no noise double\"\n",
    "    data.loc[(data[\"type\"] == \"double\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] != 0), \"double noise\"] = \"noise double\"\n",
    "    data.loc[(data[\"type\"] == \"double\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise normal\"] == 0), \"double noise precision\"] = \"noise position double\"\n",
    "    data.loc[(data[\"type\"] == \"double\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise position\"] == 0), \"double noise precision\"] = \"noise normal double\"\n",
    "\n",
    "    data.loc[(data[\"type\"] == \"float\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] == 0), \"float noise\"] = \"no noise float\"\n",
    "    data.loc[(data[\"type\"] == \"float\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise class\"] != 0), \"float noise\"] = \"noise float\"\n",
    "    data.loc[(data[\"type\"] == \"float\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise normal\"] == 0), \"float noise precision\"] = \"noise position float\"\n",
    "    data.loc[(data[\"type\"] == \"float\") & (data[\"dataset\"] == \"implicit\") & (data[\"Noise position\"] == 0), \"float noise precision\"] = \"noise normal float\"\n",
    "\n",
    "    # data[\"noise\"] = np.select(conditions, choices, default=data[\"noise\"])\n",
    "    possible_x_labels=[\"Radius\", \"Noise position\", \"Noise class\", \"Noise normal\", \"Shape\", \"type\"]\n",
    "    possible_y_labels=[\"N\", 'Nb neighbors (mean)', 'Mean curvature (mean)', 'Gaussian curvature (mean)', \"K1 mean\",\"K2 mean\",\"D1 mean\", \"D2 mean\", \"pos mean\", \"iShape mean\", \"normal mean\", \"Timings (mean)\", \"non_stable_ratio\"]\n",
    "    possible_dividers=[]\n",
    "    noise_all_double = data[\"double noise\"].unique()\n",
    "    noise_all_float = data[\"float noise\"].unique()\n",
    "\n",
    "    possible_constraints=[\n",
    "        (\"double noise\", noise_all_double, \"all double\"),\n",
    "        (\"float noise\", noise_all_float, \"all float\"),\n",
    "        (\"double noise\", [\"no noise double\"], \"No noise double\"),\n",
    "        (\"double noise\", [\"noise double\"], \"Noise double\"),\n",
    "        (\"double noise precision\", [\"noise position double\"], \"Noise position double\"),\n",
    "        (\"double noise precision\", [\"noise normal double\"], \"Noise normal double\"),\n",
    "        (\"float noise\", [\"no noise float\"], \"No noise float\"),\n",
    "        (\"float noise\", [\"noise float\"], \"Noise float\"),\n",
    "        (\"float noise precision\", [\"noise position float\"], \"Noise position float\"),\n",
    "        (\"float noise precision\", [\"noise normal float\"], \"Noise normal float\"),\n",
    "    ]\n",
    "    convert_dict_to_tsx(data, possible_x_labels, possible_y_labels, possible_dividers, possible_constraints, \"DGTal_Numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPCPNet_tsx(dataframe):\n",
    "    data = dataframe.copy()\n",
    "    data = data[data[\"expe\"] == \"PCPNet\"]\n",
    "    data = data[data[\"kNN\"] >= 0]\n",
    "    possible_x_labels=[\"kNN\", \"noise_type\", \"Shape\"]\n",
    "    possible_y_labels=[\"Timings (mean)\", \"normal mean\", \"non_stable_ratio\"]\n",
    "    possible_dividers=[]\n",
    "    \n",
    "    kNN = data[\"kNN\"].unique()\n",
    "    all_noise = data[\"Noise position\"].unique()\n",
    "    only_noise = [1, 2, 3]\n",
    "    possible_constraints=[\n",
    "        (\"kNN\", kNN, \"all\"),\n",
    "        (\"noise_type\", [\"no\"], \"No noise\"),\n",
    "        (\"noise_type\", [\"gradient\", \"striped\"], \"Density\"),\n",
    "        (\"noise_type\", [\"low\", \"med\", \"high\"], \"Noise position\"),\n",
    "    ]\n",
    "    convert_dict_to_tsx(data, possible_x_labels, possible_y_labels, possible_dividers, possible_constraints, \"PCPNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DGTal_Numerical.tsx has been created.\n"
     ]
    }
   ],
   "source": [
    "if EXPERIMENTATION == \"PCPNet\" :\n",
    "    createPCPNet_tsx(data_all)\n",
    "elif EXPERIMENTATION == \"DGTal\" :\n",
    "    createImplicit_tsx(data_all)\n",
    "elif EXPERIMENTATION == \"Numerical\" :\n",
    "    createNumerical_tsx(data_all)\n",
    "elif EXPERIMENTATION == \"CAD\" :\n",
    "    createCAD_tsx(data_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
